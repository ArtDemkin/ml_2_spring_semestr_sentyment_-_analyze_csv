import re

import alt
import streamlit as st
import pandas as pd
from nltk import ngrams
import pymorphy2
import plotly.graph_objs as go

st.set_option('deprecation.showPyplotGlobalUse', False)
st.set_page_config(layout="wide", page_title="Main_diag", page_icon="üè†")  # –ü–æ–ª–Ω–æ–æ–∫–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
alt.themes.enable('streamlit')  # –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–∏–ª—å–Ω–æ –º–µ–Ω—è–µ—Ç —Ü–≤–µ—Ç–æ–≤—É—é —Ä–∞—Å–∫–ª–∞–¥–∫—É, –Ω–æ –ø–æ—á–µ–º—É-—Ç–æ –±–µ–∑ –Ω–µ—ë –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
# –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤
st.write("# –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –ø–∞—Ä —Å–ª–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ csv —Ñ–∞–π–ª–∞")
st.sidebar.success("–ú–µ–Ω—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
number = st.number_input('–£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å:',
                         min_value=10, max_value=100)
uploaded_file = st.file_uploader("Choose a file")
if uploaded_file is not None:
    with open("out.txt", "wb") as f:
        f.write(uploaded_file.getvalue())
    st.write("File saved!")


def count_word_pairs(text):
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ Series –∏
    """
    pairs = ngrams(text.split(), 2)
    return pd.Series(pairs).value_counts()


morph = pymorphy2.MorphAnalyzer()


def lemmatize_word(word):
    """
–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—É–∏–∏ —Å–ª–æ–≤
    """
    return morph.parse(word)[0].normal_form


def words_pair():
    """
–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –ø–∞—Ä —Å–ª–æ–≤
    """
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file, encoding='utf8', sep='/n', engine='python', header=None)
        d_f = df.squeeze()
        d_f = d_f.str.lower()
        d_f = d_f.str.replace(re.compile(r'http\S+'), '', regex='True')
        d_f = d_f.str.replace(re.compile(r'[^\w\s]+'), '', regex='True')
        d_f = d_f.str.replace(re.compile(r'\d+'), '', regex='True')
        d_f = d_f.str.replace(re.compile(r'\n'), '', regex='True')
        d_f = d_f.str.replace(re.compile(r'\s{2,}'), '', regex='True')
        d_f = d_f.str.replace(re.compile(r'\s{2,}'), '', regex='True')
        d_f = d_f.apply(lambda x: ' '.join([lemmatize_word(w) for w in x.split()]))
        df_freq = d_f.apply(count_word_pairs).reset_index()
        n_largest_cols = df_freq.count().nlargest(number + 1)
        n_largest_cols.to_csv('–Ω–∞–∑–≤–∞–Ω–∏–µ_—Ñ–∞–π–ª–∞.csv')
        df = pd.read_csv('–Ω–∞–∑–≤–∞–Ω–∏–µ_—Ñ–∞–π–ª–∞.csv', encoding='utf8', sep=',', engine='python')
        df = df.drop([0])
        df[['Unnamed: 1', 'Unnamed: 2']] = df['Unnamed: 0'].str.split(' ', expand=True)
        df = df.drop('Unnamed: 0', axis=1)
        df['Unnamed: 1'] = df['Unnamed: 1'].str.replace('[^\w\s]+', '')
        df['Unnamed: 2'] = df['Unnamed: 2'].str.replace('[^\w\s]+', '')
        heatmap = go.Heatmap(
            x=df['Unnamed: 1'],
            y=df['Unnamed: 2'],
            z=df['0'],
            colorscale='brwnyl'
        )
        fig = go.Figure(data=[heatmap])
        fig.show()


print(words_pair())
